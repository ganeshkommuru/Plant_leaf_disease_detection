{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Import Packages\n",
    "'''\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import mahotas\n",
    "import cv2\n",
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Parameters\n",
    "'''\n",
    "images_per_class       = 10\n",
    "fixed_size             = tuple((500, 500))\n",
    "train_path             = \"C:\\\\Users\\\\ganesh appu\\\\Downloads\\\\project_imageprocessing\\\\Plant_leave_diseases_dataset_with_augmentation\\\\\"\n",
    "h5_train_data          = 'C:\\\\Users\\\\ganesh appu\\\\Downloads\\\\project_imageprocessing\\\\train_data.h5'\n",
    "h5_train_labels        = 'C:\\\\Users\\\\ganesh appu\\\\Downloads\\\\project_imageprocessing\\\\train_labels.h5'\n",
    "bins                   = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function for convertion of Image format from BGR TO RGB\n",
    "'''\n",
    "def rgb_bgr(image):\n",
    "    rgb_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return rgb_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Converting the Image from RGB to HSV color space\n",
    "'''\n",
    "def bgr_hsv(rgb_img):\n",
    "    hsv_img = cv2.cvtColor(rgb_img, cv2.COLOR_RGB2HSV)\n",
    "    return hsv_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Image Segmentation\n",
    "'''\n",
    "def img_segmentation(rgb_img,hsv_img):\n",
    "    lower_green = np.array([25,0,20])\n",
    "    upper_green = np.array([100,255,255])\n",
    "    healthy_mask = cv2.inRange(hsv_img, lower_green, upper_green)\n",
    "    result = cv2.bitwise_and(rgb_img,rgb_img, mask=healthy_mask)\n",
    "    lower_brown = np.array([10,0,10])\n",
    "    upper_brown = np.array([30,255,255])\n",
    "    disease_mask = cv2.inRange(hsv_img, lower_brown, upper_brown)\n",
    "    disease_result = cv2.bitwise_and(rgb_img, rgb_img, mask=disease_mask)\n",
    "    final_mask = healthy_mask + disease_mask\n",
    "    final_result = cv2.bitwise_and(rgb_img, rgb_img, mask=final_mask)\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Global Feature: 1 Shape\n",
    "Hu moments\n",
    "'''\n",
    "def fd_hu_moments(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    feature = cv2.HuMoments(cv2.moments(image)).flatten()\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Global Feature: 2 Texture\n",
    "Haralick Texture\n",
    "'''\n",
    "def fd_haralick(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    haralick = mahotas.features.haralick(gray).mean(axis=0)\n",
    "    return haralick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Global Feature: 3 Color\n",
    "'''\n",
    "def fd_histogram(image, mask=None):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist  = cv2.calcHist([image], [0, 1, 2], None, [bins, bins, bins], [0, 256, 0, 256, 0, 256])\n",
    "    cv2.normalize(hist, hist)\n",
    "    return hist.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy', 'Background_without_leaves', 'Blueberry___healthy', 'Cherry___Powdery_mildew', 'Cherry___healthy', 'Corn___Cercospora_leaf_spot Gray_leaf_spot', 'Corn___Common_rust', 'Corn___Northern_Leaf_Blight', 'Corn___healthy', 'Grape___Black_rot', 'Grape___Esca_(Black_Measles)', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Grape___healthy', 'Orange___Haunglongbing_(Citrus_greening)', 'Peach___Bacterial_spot', 'Peach___healthy', 'Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy', 'Raspberry___healthy', 'Soybean___healthy', 'Squash___Powdery_mildew', 'Strawberry___Leaf_scorch', 'Strawberry___healthy', 'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___Late_blight', 'Tomato___Leaf_Mold', 'Tomato___Septoria_leaf_spot', 'Tomato___Spider_mites Two-spotted_spider_mite', 'Tomato___Target_Spot', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Tomato___Tomato_mosaic_virus', 'Tomato___healthy']\n"
     ]
    }
   ],
   "source": [
    "train_labels = os.listdir(train_path)\n",
    "train_labels.sort()\n",
    "print(train_labels)\n",
    "global_features = []\n",
    "labels          = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ganesh appu\\\\Downloads\\\\project_imageprocessing'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed folder: Apple___Apple_scab\n",
      "processed folder: Apple___Black_rot\n",
      "processed folder: Apple___Cedar_apple_rust\n",
      "processed folder: Apple___healthy\n",
      "processed folder: Background_without_leaves\n",
      "processed folder: Blueberry___healthy\n",
      "processed folder: Cherry___Powdery_mildew\n",
      "processed folder: Cherry___healthy\n",
      "processed folder: Corn___Cercospora_leaf_spot Gray_leaf_spot\n",
      "processed folder: Corn___Common_rust\n",
      "processed folder: Corn___Northern_Leaf_Blight\n",
      "processed folder: Corn___healthy\n",
      "processed folder: Grape___Black_rot\n",
      "processed folder: Grape___Esca_(Black_Measles)\n",
      "processed folder: Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\n",
      "processed folder: Grape___healthy\n",
      "processed folder: Orange___Haunglongbing_(Citrus_greening)\n",
      "processed folder: Peach___Bacterial_spot\n",
      "processed folder: Peach___healthy\n",
      "processed folder: Pepper,_bell___Bacterial_spot\n",
      "processed folder: Pepper,_bell___healthy\n",
      "processed folder: Potato___Early_blight\n",
      "processed folder: Potato___Late_blight\n",
      "processed folder: Potato___healthy\n",
      "processed folder: Raspberry___healthy\n",
      "processed folder: Soybean___healthy\n",
      "processed folder: Squash___Powdery_mildew\n",
      "processed folder: Strawberry___Leaf_scorch\n",
      "processed folder: Strawberry___healthy\n",
      "processed folder: Tomato___Bacterial_spot\n",
      "processed folder: Tomato___Early_blight\n",
      "processed folder: Tomato___Late_blight\n",
      "processed folder: Tomato___Leaf_Mold\n",
      "processed folder: Tomato___Septoria_leaf_spot\n",
      "processed folder: Tomato___Spider_mites Two-spotted_spider_mite\n",
      "processed folder: Tomato___Target_Spot\n",
      "processed folder: Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "processed folder: Tomato___Tomato_mosaic_virus\n",
      "processed folder: Tomato___healthy\n",
      "completed Global Feature Extraction...\n"
     ]
    }
   ],
   "source": [
    "for training_name in train_labels:\n",
    "    dir = os.path.join(train_path, training_name)\n",
    "\n",
    "    current_label = training_name\n",
    "    #Images in each file\n",
    "    for x in range(1,images_per_class+1):\n",
    "        file = dir + \"\\\\\" + \"image (\" +str(x) + \")\" +\".jpg\"\n",
    "\n",
    "        # Reading the image and converting it to required size\n",
    "        image = cv2.imread(file)\n",
    "        image = cv2.resize(image, fixed_size)\n",
    "\n",
    "        \n",
    "        # Calling Functions\n",
    "        \n",
    "        RGB_BGR       = rgb_bgr(image)\n",
    "        BGR_HSV       = bgr_hsv(RGB_BGR)\n",
    "        IMG_SEGMENT   = img_segmentation(RGB_BGR,BGR_HSV)\n",
    "\n",
    "        # Extracting Features\n",
    "        \n",
    "        fv_hu_moments = fd_hu_moments(IMG_SEGMENT)\n",
    "        fv_haralick   = fd_haralick(IMG_SEGMENT)\n",
    "        fv_histogram  = fd_histogram(IMG_SEGMENT)\n",
    "        \n",
    "        global_feature = np.hstack([fv_histogram, fv_haralick, fv_hu_moments])\n",
    "        \n",
    "        #Storing the features\n",
    "        labels.append(current_label)\n",
    "        global_features.append(global_feature)\n",
    "\n",
    "    print(\"processed folder: {}\".format(current_label))\n",
    "\n",
    "print(\"completed Global Feature Extraction...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Features are (390, 532)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Overall vector size used for training the model is\n",
    "'''\n",
    "print(\"No of Features are {}\".format(np.array(global_features).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Labels (390,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Overall Training Label size\n",
    "'''\n",
    "print(\"Training Labels {}\".format(np.array(labels).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels encoded\n"
     ]
    }
   ],
   "source": [
    "# Encoding the Training Labels to Decrease the size\n",
    "targetNames = np.unique(labels)\n",
    "le          = LabelEncoder()\n",
    "target      = le.fit_transform(labels)\n",
    "print(\"Training labels encoded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vector normalized\n"
     ]
    }
   ],
   "source": [
    "#Normalizing the feature vectors for size reduction\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler            = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaled_features = scaler.fit_transform(global_features)\n",
    "print(\"Feature vector normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target labels: [ 0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  1  1  2  2  2  2\n",
      "  2  2  2  2  2  2  3  3  3  3  3  3  3  3  3  3  4  4  4  4  4  4  4  4\n",
      "  4  4  5  5  5  5  5  5  5  5  5  5  6  6  6  6  6  6  6  6  6  6  7  7\n",
      "  7  7  7  7  7  7  7  7  8  8  8  8  8  8  8  8  8  8  9  9  9  9  9  9\n",
      "  9  9  9  9 10 10 10 10 10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11\n",
      " 12 12 12 12 12 12 12 12 12 12 13 13 13 13 13 13 13 13 13 13 14 14 14 14\n",
      " 14 14 14 14 14 14 15 15 15 15 15 15 15 15 15 15 16 16 16 16 16 16 16 16\n",
      " 16 16 17 17 17 17 17 17 17 17 17 17 18 18 18 18 18 18 18 18 18 18 19 19\n",
      " 19 19 19 19 19 19 19 19 20 20 20 20 20 20 20 20 20 20 21 21 21 21 21 21\n",
      " 21 21 21 21 22 22 22 22 22 22 22 22 22 22 23 23 23 23 23 23 23 23 23 23\n",
      " 24 24 24 24 24 24 24 24 24 24 25 25 25 25 25 25 25 25 25 25 26 26 26 26\n",
      " 26 26 26 26 26 26 27 27 27 27 27 27 27 27 27 27 28 28 28 28 28 28 28 28\n",
      " 28 28 29 29 29 29 29 29 29 29 29 29 30 30 30 30 30 30 30 30 30 30 31 31\n",
      " 31 31 31 31 31 31 31 31 32 32 32 32 32 32 32 32 32 32 33 33 33 33 33 33\n",
      " 33 33 33 33 34 34 34 34 34 34 34 34 34 34 35 35 35 35 35 35 35 35 35 35\n",
      " 36 36 36 36 36 36 36 36 36 36 37 37 37 37 37 37 37 37 37 37 38 38 38 38\n",
      " 38 38 38 38 38 38]\n",
      "Target labels shape: (390,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Target labels: {}\".format(target))\n",
    "print(\"Target labels shape: {}\".format(target.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"dataset#1\": shape (390, 532), type \"<f8\">"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To save the feature vector on the local system\n",
    "h5f_data = h5py.File(h5_train_data, 'w')\n",
    "h5f_data.create_dataset('dataset#1', data=np.array(rescaled_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"dataset#1\": shape (390,), type \"<i8\">"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To save target labels\n",
    "h5f_label = h5py.File(h5_train_labels, 'w')\n",
    "h5f_label.create_dataset('dataset#1', data=np.array(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f_data.close()\n",
    "h5f_label.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
